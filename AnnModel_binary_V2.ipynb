{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oY8uTBZln8ky"
      },
      "outputs": [],
      "source": [
        "%run /content/AnnModel2.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W4bfaq4zobgi"
      },
      "outputs": [],
      "source": [
        "# 메인 메서드의 매개변수 추가\n",
        "def binary_main(epoch_count = 10, mb_size = 10, report=1, train_ratio = 0.6, adjust_ratio = False):\n",
        "    binary_load_dataset(adjust_ratio)\n",
        "    init_param()\n",
        "    train_and_test(epoch_count,mb_size,report,train_ratio)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FefsBYAbokR6"
      },
      "outputs": [],
      "source": [
        "# 메서드 정의 \n",
        "\n",
        "# 매개변수 \n",
        "# adjust_ratio: 본 메서드에는 비율 조정에 대한 매개변수 adjust_ratio 를 할당하도록 합니다. \n",
        "# 해당 매개변수가 참(True)인 경우에만 데이터를 복사할 수 있도록 합니다. \n",
        "def binary_load_dataset(adjust_ratio:bool):\n",
        "    \n",
        "    # 이번에는 pulsars 데이터를 복사해야 하므로, 각 변수를 따로 저정할 필요가 있습니다. \n",
        "    # 그렇기에 두 변수를 담을 수 있는 빈 리스트를 정의합니다. \n",
        "    pulsars, stars = [],[]\n",
        "\n",
        "    # 이전과 마찬가지로 데이터를 열고, 읽는 과정이 필요합니다. \n",
        "    with open('.../binary_classification_data.csv') as csvfile: \n",
        "        csvreader = csv.reader(csvfile)\n",
        "        next(csvreader)\n",
        "\n",
        "\n",
        "        '''데이터를 나눠 저장하는 과정'''\n",
        "        # 현재 csvreader 변수는 마지막 열에 종속변수가 들어있기에, \n",
        "        # 해당 열의 인덱스를 기준으로 '1' 과 '0' 에 대하여 각각 빈 리스트에 할당시켜 줍니다. \n",
        "        for row in csvreader:\n",
        "            \n",
        "            # 펄서(1) 저장\n",
        "            if row[8] == '1' : \n",
        "                pulsars.append(row)\n",
        "\n",
        "            # 별(0) 저장\n",
        "            else:\n",
        "                stars.append(row)\n",
        "\n",
        "    # 실험에 쓰일 데이터와 신경망의 입출력 크기를 전역변수로 선언합니다. \n",
        "    # pulsars, stars에 속한 데이터는 data 변수에 하나로 묶어줄 것 입니다. \n",
        "    global data, input_cnt, output_cnt\n",
        "    input_cnt, output_cnt = 8,1\n",
        "\n",
        "    # pulsars 데이터를 stars 데이터 수에 맞춰주기 위해서는 각 데이터의 개수를 파악할 필요가 있습니다.  \n",
        "    star_cnt, pulsar_cnt = len(stars), len(pulsars)\n",
        "\n",
        "    \n",
        "    '''매개변수의 값이 True 인 경우 pulsars 데이터의 비율을 늘려주도록 합니다.'''\n",
        "    if adjust_ratio:\n",
        "\n",
        "        # 앞서 Star 데이터와 Pulsar 데이터는 각각 변수처리하였으나, \n",
        "        # 결국 두 데이터는 하나의 변수에 담아주어야 합니다. \n",
        "        # 그렇기에 두 데이터를 담을 수 있는 하나의 변수 data를 생성하며,\n",
        "        # 해당 데이터의 크기는 star_cnt의 2배수로 저장합니다. \n",
        "        # 이유는 기존 stars 변수의 수 만큼 pulsars 변수의 수를 증가시켜 \n",
        "        # 같은 수로 맞춰주기 위함입니다. \n",
        "        data = np.zeros([2 * star_cnt, 9])\n",
        "\n",
        "        '''[stars 변수의 data 변수 할당 과정]'''\n",
        "        # 할당 범위는 첫 번째 행부터 star_cnt 행 까지 \n",
        "        data[0:star_cnt, :] = np.asarray(stars, dtype=\"float32\")\n",
        "\n",
        "        '''[pulsar 변수의 data 변수 할당 과정]'''\n",
        "        # stars 변수의 수 만큼 반복하여 pulsars 데이터를 증가시켜주어야 합니다. \n",
        "        # 그렇기에 data 변수의 pulsars 데이터 할당 범위는 data[star_cnt+n] 부터 이뤄저야 하죠. \n",
        "\n",
        "        # 예시) star 변수와 pulsar 변수가 다음과 같이 존재합니다. \n",
        "        # star = [a,b,c,d,e]\n",
        "        # pulsar = [1,2]\n",
        "\n",
        "        # 이러한 상황에서 data 의 변수에는 다음과 같이 데이터가 할당되어야 합니다. \n",
        "        # data = [a,b,c,d,e,1,2,1,2,1]\n",
        "        # 이를 고려하였을 때 pulsar 데이터의 인덱스를 순차적으로 뽑아내야 합니다. \n",
        "        \n",
        "        # 파이썬의 % 연산자는 나머지를 반환하는 성질을 갖고 있으며, \n",
        "        # a % b 결괏값인 몫이 0 이하인 경우 a 를 그대로 반환합니다.  \n",
        "        \"\"\" 0 % 3 = 0\n",
        "            1 % 3 = 1\n",
        "            2 % 3 = 2 \n",
        "            3 % 3 = 0\n",
        "            4 % 3 = 1 \"\"\"\n",
        "        # 이 점을 활용하여 pulsar 데이터를 star 데이터의 개수(star_cnt)만큼 반복해서 뽑아내줍니다. \n",
        "\n",
        "        for n in range(star_cnt):\n",
        "            # 뽑아낸 데이터는 data[star_cnt+n] 인덱스에 할당시켜줍니다.\n",
        "            data[star_cnt+n] = np.asarray(pulsars[n % pulsar_cnt], dtype='float32')\n",
        "\n",
        "\n",
        "    \n",
        "    # 매개변수의 값이 False 인 경우 \n",
        "    # 기존 데이터를 data 변수에 그대로 할당시킵니다.\n",
        "    else:\n",
        "        data = np.zeros([star_cnt+pulsar_cnt,9])\n",
        "        data[0:star_cnt, :] = np.asarray(stars, dtype='float32')\n",
        "        data[star_cnt:,:] = np.asarray(pulsars, dtype='float32')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ACIbqqlEo0uY"
      },
      "outputs": [],
      "source": [
        "# 메서드 재정의 \n",
        "def eval_accuracy(y_hat,y_real):\n",
        "\t\t\n",
        "\t# 앞서 평가지표를 정의했던 코드를 그대로 가지고 옵니다. \n",
        "    est_yes = np.greater(y_hat,0)\n",
        "    ans_yes = np.greater(y_real, 0.5)\n",
        "\n",
        "    est_no = np.logical_not(est_yes) \n",
        "    ans_no = np.logical_not(ans_yes)\n",
        "\n",
        "    tp = np.sum(np.logical_and(est_yes, ans_yes))\n",
        "    tn = np.sum(np.logical_and(est_no, ans_no))\n",
        "    fp = np.sum(np.logical_and(ans_no, est_yes))\n",
        "    fn = np.sum(np.logical_and(ans_yes, est_no))\n",
        "\t\t\n",
        "\t# 안전한 나눗셈 메서드를 활용하여 줍니다. \n",
        "    accuracy = safe_div(tp+tn,tp+fp+fn+tn)\n",
        "    precision = safe_div(tp,tp+fp)\n",
        "    recall = safe_div(tp,tp+fn)\n",
        "    f1 = 2 * safe_div(recall*precision,recall+precision)\n",
        "\t\t\n",
        "\t# 평가 결괏값은 4개지만, 하나의 변수로 반환하기 위해 리스트로 묶어 주었습니다. \n",
        "    return [accuracy, precision, recall, f1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YbohJdd8pDJp"
      },
      "outputs": [],
      "source": [
        "# 메서드 정의\n",
        "def safe_div(p, q):\n",
        "\n",
        "    # 매개변수의 데이터 타입을 통일시켜 줍니다. \n",
        "    p, q = float(p), float(q)\n",
        "\n",
        "    # 경우 1) \n",
        "    # accuracy = (tp+tn)/(tp+fp+fn+tn)\n",
        "    # precision = tp/(tp+fp)\n",
        "    # recall = (tp)/(tp+fn)\n",
        "    \n",
        "    # 위 세 가지 수식을 살펴보면 분모의 연산 결괏값이 0 인 경우 분자의 결괏값 또한 무조건 0 이 됩니다. \n",
        "    # 즉 분모의 값이 매우 작은 값(0 이하)이라면 안전하게 0 을 반환시켜야 됩니다. \n",
        "    if np.abs(q) < 1.0e-20:\n",
        "        \n",
        "        # np.sign() 메서드를 활용해 0 을 반환시켜줍니다.\n",
        "        return np.sign(p)\n",
        "\n",
        "    # 경우 2) \n",
        "    # 분모의 값이 0보다 조금이라도 크다면 일반적인 나눗셈을 수행시켜주어야 합니다. \n",
        "    return p / q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NS5PGpjjpGty"
      },
      "outputs": [],
      "source": [
        "# 메서드 재정의 \n",
        "def train_and_test(epoch_count, mb_size, report, train_ratio):\n",
        "    \n",
        "    ''' train_and_test() 메서드의 기존 프로세스는 그대로 유지합니다. '''\n",
        "\n",
        "    #1) 데이터 셔플링 - arrange_data()\n",
        "    mini_batch_step_count = arrange_data(mb_size,train_ratio)\n",
        "    \n",
        "    #2) 테스트 데이터 분리 - get_test_data()\n",
        "    test_x, test_y = get_test_data()\n",
        "    \n",
        "    for epoch in range(epoch_count):\n",
        "\n",
        "        # 4개의 평가지표를 담는 빈 리스트 생성 \n",
        "        losses = []\n",
        "\n",
        "        for nth in range(mini_batch_step_count):\n",
        "            # 3) 학습 데이터 분리 - get_test_data()'''\n",
        "            train_x, train_y  = get_train_data(mb_size, nth)           \n",
        "            \n",
        "            # 4) 학습 - run_train()\n",
        "            # 학습 데이터 기반의 미니배치에 따른 손실지표 cross entropy 를 반환 합니다.\n",
        "            # run_train() 메서드의 두 번째 반환값 정확도는 굳이 표기하지 않기에 '_' 처리 합니다. \n",
        "            loss, _           = run_train(train_x,train_y)\n",
        "            \n",
        "            # 1 에폭에 따른 미니배치들의 손실값 평균을 내기 위해 값을 저장합니다.\n",
        "            losses.append(loss)\n",
        "            \n",
        "        # 평가 및 출력은 매번 하지 않고 일정 주기마다 수행 합니다. \n",
        "        if report > 0 and (epoch+1) % report == 0:\n",
        "            \n",
        "            # 에폭에 따른 테스트 데이터 기반의 성능 평가 \n",
        "            acc = run_test(test_x, test_y)\n",
        "            # 학습 데이터 기반의 손실값 출력 / 테스트 데이터 기반의 평가지표 출력\n",
        "            print(\"[Epoch {}] Train Loss = {:.3f} | Test Acc = {:.3f}, Precision = {:.3f}, Recall = {:.3f}, F1 = {:.3f}\".\\\n",
        "                  format(epoch+1, np.mean(losses), acc[0],acc[1],acc[2],acc[3]))\n",
        "            \n",
        "    #5) 최종 테스트 - run_test()\n",
        "    final_acc = run_test(test_x, test_y)\n",
        "    # 평가 결과를 출력합니다. \n",
        "    print(\"\\n\",\"=\"*40, ' FINAL TEST REPORT', '='*40,\"\\n\")\n",
        "    print(\"► Acc = {:.3f} Precision = {:.3f}, Recall = {:.3f}, F1 = {:.3f}\".\\\n",
        "                  format(final_acc[0],final_acc[1],final_acc[2],final_acc[3]))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
