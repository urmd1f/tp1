{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "574h7Lu5be-8"
      },
      "outputs": [],
      "source": [
        "def set_hidden(info):\n",
        "    # hidden_cnt : 하나의 은닉계층인 경우 해당 은닉계층이 갖는 노드의 수\n",
        "\t# hidden_config : 다수의 은닉계층인 경우 해당 은닉계층들의 수와 노드의 수\n",
        "    global hidden_cnt, hidden_config\n",
        "\n",
        "    # 은닉계층 셋팅 과정에서 int 형식으로 들어오는 경우와 리스트 형식으로 들어오는 경우를 분리하였습니다. \n",
        "\t# int 형식은 하나의 은닉계층으로 고정\n",
        "    # list 형식은 하나 이상의 은닉계층 \n",
        "    # isinstance() 는 첫 번째 매개변수 타입과 두 번째 매개변수 타입이 일치하는지 확인합니다. \n",
        "    if isinstance(info, int):\n",
        "        hidden_cnt = info      # int 형식이 맞는 경우 hidden_cnt 변수에 은닉 계층의 노드 수를 할당 \n",
        "        hidden_config = None   # int 형식이 맞는 경우 hidden_config 변수는 None 처리\n",
        "    \n",
        "\t# 사용자의 설정값이 list 형식인 경우 해당 info 에 담긴 값은 hidden_config 변수에 할당\n",
        "    else:\n",
        "        hidden_config = info"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ng23ZRP0eise"
      },
      "outputs": [],
      "source": [
        "# 기존에 파라미터를 초기화 하는 메서드의 재정의 입니다. \n",
        "def init_param():\n",
        "    \n",
        "\t# 사용자가 정의한 은닉 계층의 정보에 따라 hidden_config 변수의 타입은 None 혹은 List로 지정됩니다. \n",
        "\t# hidden_config 변수의 타입이 None 이 아닌 경우 하나 이상의 은닉 계층을 갖으므로, 그에 따른 파라미터 초기화 메서드를 동작시킵니다. \n",
        "    if hidden_config is not None:\n",
        "\t\t# 사용자를 위한 은닉계층 안내 문구 출력 및 다수의 파라미터 생성을 위한 메서드 동작 \n",
        "        print(f\"[안내] 은닉 계층 {len(hidden_config)}개를 갖는 다층 퍼셉트론이 적용됩니다.\")\n",
        "        init_param_hiddens() # 본 메서드는 곧 정의할 예정입니다. \n",
        "\t\n",
        "    # hidden_config 변수의 타입이 None 인 경우 하나의 은닉 계층을 갖으므로, 그에 따른 파라미터 초기화 메서드를 동작시킵니다. \n",
        "    else:\n",
        "\t\t# 사용자를 위한 은닉계층 안내 문구 출력 및 다수의 파라미터 생성을 위한 메서드 동작 \n",
        "        print(\"[안내] 은닉 계층 하나를 갖는 다층 퍼셉트론이 적용됩니다.\")\n",
        "        init_param_hidden1() # 본 메서드는 곧 정의할 예정입니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yS0o_kkxex3p",
        "outputId": "02a0fb37-da11-4802-8514-47d8c51181e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[안내] 은닉 계층 2개를 갖는 다층 퍼셉트론이 적용됩니다.\n",
            "init_param_hiddens() 가 동작하였습니다.\n",
            "[안내] 은닉 계층 하나를 갖는 다층 퍼셉트론이 적용됩니다.\n",
            "init_param_hidden1() 가 동작하였습니다.\n"
          ]
        }
      ],
      "source": [
        "# # [테스트 코드]\n",
        "# # 테스트를 위해 간단히 메서드의 동작 확인만 수행할 수 있도록 정의하였습니다. \n",
        "# def init_param_hiddens():\n",
        "#     print(\"init_param_hiddens() 가 동작하였습니다.\")\n",
        "\n",
        "# def init_param_hidden1():\n",
        "#     print(\"init_param_hidden1() 가 동작하였습니다.\")\n",
        "\n",
        "# # 하나 이상의 은닉계층을 설정하는 경우\n",
        "# set_hidden([5,3])\n",
        "# init_param()\n",
        "\n",
        "# # 하나의 은닉계층만을 설정하는 경우\n",
        "# set_hidden(5)\n",
        "# init_param()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "QFk0Tu1Ue0uS"
      },
      "outputs": [],
      "source": [
        "# 기존에 신경망의 선형연산을 수행하는 메서드를 재정의 합니다. \n",
        "# 선형연산에 필요한 독립변수가 담긴 변수를 매개변수로 취합니다. \n",
        "def forward_neuralnet(x):\n",
        "    # 사용자가 정의한 은닉 계층에 따라 hidden_config 변수의 타입은 None 혹은 List로 지정됩니다. \n",
        "    # hidden_config 변수의 타입이 None 이 아닌 경우 하나 이상의 은닉 계층을 갖으므로, 그에 따른 선형연산 메서드를 동작시킵니다. \n",
        "    if hidden_config is not None:\n",
        "        return forward_neuralnet_hiddens(x)\n",
        "    \n",
        "    # hidden_config 변수의 타입이 None 인 경우 하나의 은닉 계층을 갖으므로, 그에 따른 선형연산 메서드를 동작시킵니다. \n",
        "    else:\n",
        "        return forward_neuralnet_hidden1(x)\n",
        "\n",
        "# 기존에 경사하강법에 따른 파라미터 업데이트 메서드를 재정의 합니다. \n",
        "# 위 방식과 마찬가지로 hidden_config 변수타입에 맞춰 동작하는 메서드를 달리합니다. \n",
        "# 매개변수는 경사하강법에 필요한 변수들을 취합니다. \n",
        "def backprop_neuralnet(G_output, hiddens):\n",
        "    if hidden_config is not None:\n",
        "        backprop_neuralnet_hiddens(G_output, hiddens)\n",
        "    else:\n",
        "        backprop_neuralnet_hidden1(G_output, hiddens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V5t83kB9fJzI",
        "outputId": "5a447330-3b47-43ad-815f-2905e23488a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "forward_neuralnet_hiddens() 메서드가 동작하였습니다.\n",
            "backprop_neuralnet_hiddens() 메서드가 동작하였습니다.\n",
            "forward_neuralnet_hidden1() 메서드가 동작하였습니다.\n",
            "backprop_neuralnet_hidden1() 메서드가 동작하였습니다.\n"
          ]
        }
      ],
      "source": [
        "# # [테스트 코드]\n",
        "# # 메서드 동작 테스트에 필요한 내부 메서드는 사전에 간단히 정의합니다.\n",
        "# def forward_neuralnet_hidden1(x):\n",
        "#     print(\"forward_neuralnet_hidden1() 메서드가 동작하였습니다.\")\n",
        "\n",
        "# def forward_neuralnet_hiddens(x):\n",
        "#     print(\"forward_neuralnet_hiddens() 메서드가 동작하였습니다.\")\n",
        "\n",
        "# def backprop_neuralnet_hidden1(G_output, hiddens):\n",
        "#     print(\"backprop_neuralnet_hidden1() 메서드가 동작하였습니다.\")\n",
        "\n",
        "# def backprop_neuralnet_hiddens(G_output, hiddens):\n",
        "#     print(\"backprop_neuralnet_hiddens() 메서드가 동작하였습니다.\")\n",
        "\n",
        "\n",
        "# # 은닉 계층이 하나 이상인 경우에 대한 동작 테스트\n",
        "# set_hidden([5,3])\n",
        "# forward_neuralnet(x=[1,2,3])\n",
        "# backprop_neuralnet(G_output=0, hiddens=[0])\n",
        "\n",
        "# # 은닉 계층이 하나인 경우에 대한 동작 테스트\n",
        "# set_hidden(5)\n",
        "# forward_neuralnet(x=[1,2,3])\n",
        "# backprop_neuralnet(G_output=0, hiddens=[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ywFn7szxfLpv"
      },
      "outputs": [],
      "source": [
        "# 계층 사이의 파라미터 초기화를 진행하는 메서드\n",
        "# shape : 다음과 같은 리스트 형식으로 값을 전달받습니다. \n",
        "# ex) 독립변수 5개, 은닉계층의 노드 3개인 경우 [5,3]\n",
        "# ex) 은닉계층의 노드 수 3개, 출력계층의 노드 수 1개인 경우 [3,1]\n",
        "def allocate_param_pair(shape):\n",
        "    # [가중치 초기화 과정]\n",
        "    weight = np.random.normal(RND_MEAN, RND_STD, shape)\n",
        "\t\t\n",
        "\t# [편향 초기화 과정]\n",
        "    # 편향은 리스트 형식으로 값을 전달받는 것을 고려하여 -1 인덱스를 활용 \n",
        "    bias   = np.zeros(shape[-1])\n",
        "    \n",
        "    # 파이썬의 데이터 타입 중 딕셔너리 구조로 정의합니다.\n",
        "\t# 가중치는 'w', 편향은 'b' 키로 접근하여 활용할 수 있도록 합니다. \n",
        "    return {'w':weight, 'b':bias}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dS7jEEmdfUlc",
        "outputId": "69a4f7b6-34d3-4fc3-a1cd-63c92ce4f672"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "pm_hidden['w'] : \n",
            " [[-1.08555064  0.45349557  0.5704524 ]\n",
            " [-0.58646491  0.29405928 -0.36085675]\n",
            " [ 1.09889272  1.26754809  0.23032462]\n",
            " [ 0.42614718  0.60521273 -2.61894139]\n",
            " [ 0.66169636 -0.24841217  0.24210593]]\n",
            "pm_hidden['b'] : \n",
            " [0. 0. 0.]\n"
          ]
        }
      ],
      "source": [
        "# # [테스트 코드]\n",
        "# import numpy as np\n",
        "# RND_MEAN, RND_STD = 0.0, 1.0\n",
        "\n",
        "# # 입력 벡터의 노드 수 5개, 은닉 계층의 노드 수 3개 인 경우 해당 계층 사이에 존재하는 파라미터는 다음과 같습니다. \n",
        "# # 가중치 15개, 편향 3개\n",
        "# pm_hidden = allocate_param_pair([5,3])\n",
        "\n",
        "# print(\"pm_hidden['w'] : \\n\", pm_hidden['w'])\n",
        "# print(\"pm_hidden['b'] : \\n\", pm_hidden['b'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "GqP9arBVfWcn"
      },
      "outputs": [],
      "source": [
        "# 하나의 은닉계층을 갖는 신경망의 파라미터변수 생성 메서드\n",
        "def init_param_hidden1():\n",
        "\n",
        "    # 추후 활용을 위한 전역변수 지정 \n",
        "    global pm_output, pm_hidden, input_cnt, output_cnt, hidden_cnt\n",
        "    # input_cnt  : 사전 신경망 모델이 들어있는 파일에 정의된 입력 계층의 노드 수 (독립변수의 수)\n",
        "\t# output_cnt : 사전 신경망 모델이 들어있는 파일에 정의된 출력 계층의 노드 수 (종속변수의 수) \n",
        "    # pm_hidden : 입력계층과 은닉계층 사이에 존재하는 파라미터 \n",
        "    # pm_output : 은닉계층과 출력계층 사이에 존재하는 파라미터\n",
        "\t\n",
        "\t# 사전에 정의한 allocate_param_pair() 메서드를 통해 계층과 계층사이의 파라미터가 담긴 변수를 생성합니다.\n",
        "    pm_hidden = allocate_param_pair([input_cnt, hidden_cnt])\n",
        "    pm_output = allocate_param_pair([hidden_cnt, output_cnt])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yutEcPDbfqvQ",
        "outputId": "47f333a2-8a08-4ea7-f319-7135fb05399c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[안내] 은닉 계층 하나를 갖는 다층 퍼셉트론이 적용됩니다.\n",
            "pm_hidden['w'] : \n",
            " [[ 0.23273787 -0.10147398 -1.79204791 -0.27585731 -1.14332498]\n",
            " [-0.01186774 -0.75470212 -1.13303918 -0.87025825 -0.5799043 ]\n",
            " [ 0.01975917 -0.12883493 -1.03657366  0.09333956  1.02372487]\n",
            " [ 0.46834702  0.18401411 -1.74772986  0.19509036  0.28003816]\n",
            " [-0.11868864  0.16128031 -0.09876373 -0.75860641 -1.72332409]\n",
            " [ 0.40693419  0.98749527  0.98833146  1.55562455 -0.23900974]\n",
            " [-0.27195183 -0.21114052  1.16280308 -0.28756222 -0.55880304]\n",
            " [-1.28274662 -1.06401459 -2.02448528 -0.7420376  -0.28105869]\n",
            " [-1.21637909  0.32803621 -1.08617391 -0.64992691  0.29760718]\n",
            " [-0.19187041  0.93628244  0.07099527  0.99132808  0.03519953]]\n",
            "pm_hidden['b'] : \n",
            " [0. 0. 0. 0. 0.]\n",
            "pm_output['w'] : \n",
            " [[ 1.4365505 ]\n",
            " [-0.38229252]\n",
            " [ 1.72250051]\n",
            " [ 0.33068309]\n",
            " [ 0.17534596]]\n",
            "pm_output['b'] : \n",
            " [0.]\n"
          ]
        }
      ],
      "source": [
        "# # [테스트 코드]\n",
        "# # 다층 퍼셉트론 신경망 구조 설정\n",
        "# input_cnt = 10  # 입력계층의 노드 수 10개 \n",
        "# set_hidden(5)   # 은닉계층의 노드 수 5개\n",
        "# output_cnt = 1  # 출력계층의 노드 수 1개 \n",
        "\n",
        "# # 파라미터 초기화 메서드 동작 시나리오\n",
        "# # init_param() -> init_param_hidden1() -> allocate_param_pair()\n",
        "# init_param()\n",
        "\n",
        "# print(\"pm_hidden['w'] : \\n\", pm_hidden['w'])\n",
        "# print(\"pm_hidden['b'] : \\n\", pm_hidden['b'])\n",
        "# print(\"pm_output['w'] : \\n\", pm_output['w'])\n",
        "# print(\"pm_output['b'] : \\n\", pm_output['b'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "ZhnC92Eof3Sp"
      },
      "outputs": [],
      "source": [
        "# 다수의 은닉계층이 있는 경우 각 계층 사이에 존재하는 파라미터 변수 생성 메서드\n",
        "def init_param_hiddens():\n",
        "    # input_cnt    : 입력계층의 노드 수\n",
        "    # output_cnt   : 출력계층의 노드 수 \n",
        "    # hidden_config : 은닉계층에 대한 정보 \n",
        "    # pm_hiddens: [입력계층]-> (파라미터{pm_hiddens}) ->[은닉계층]--> (파라미터{pm_hiddens}) -->[마지막 은닉계층]--> ...\n",
        "    # pm_output : [마지막 은닉계층]-> (파라미터{pm_output}) ->[출력계층]\n",
        "    global pm_output, pm_hiddens, input_cnt, output_cnt, hidden_config\n",
        "\n",
        "    # 입력계층부터 마지막 은닉계층 사이에 존재하는 파라미터 값을 저장하기 위한 빈리스트 사전 정의 \n",
        "    # 마지막 은닉계층과 출력 계층 사이의 파라미터는 따로 변수를 둘 예정 \n",
        "    pm_hiddens = []\n",
        "\n",
        "    # 반복문을 활용하여 파라미터를 생성할 예정이기에 input_cnt 변수의 값을\n",
        "    # prev_cnt 변수에 할당합니다. \n",
        "    prev_cnt = input_cnt\n",
        "\n",
        "    # hidden_config:list -> 은닉계층의 수와 폭 정보\n",
        "    # Ex) 6, [3,7], [3,6,9], ...\n",
        "    for hidden_cnt in hidden_config:\n",
        "        \n",
        "        # 입력계층(prev_cnt)과 첫번째 은닉계층(hidden_cnt)의 파라미터 생성\n",
        "        # 해당 계층 사이의 파라미터는 pm_hiddens 변수에 쌓는다. \n",
        "        pm_hiddens.append(allocate_param_pair([prev_cnt, hidden_cnt]))\n",
        "        \n",
        "        # 은닉 계층의 노드 수 정보를 prev_cnt 변수로 할당하여 allocate_param_pair()를 통해\n",
        "        # 다시 은닉 계층들 사이의 파라미터 변수를 생성할 수 있도록 합니다. \n",
        "        prev_cnt = hidden_cnt\n",
        "        # 모든 은닉계층들의 파라미터 생성을 마치면 반복문 탈출\n",
        "\n",
        "    # 마지막 은닉계층(prev_cnt)과 출력계층(output_cnt) 사이의 파라미터 생성 및 변수 생성  \n",
        "    pm_output = allocate_param_pair([prev_cnt, output_cnt])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ed-T7qgLgFvD",
        "outputId": "664673ad-a131-4c05-8afa-ea350bdc77c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[안내] 은닉 계층 2개를 갖는 다층 퍼셉트론이 적용됩니다.\n",
            "입력계층과 첫 번째 은닉계층 사이의 가중치 : \n",
            " [[ 0.23069819  0.10863501  1.28052735  1.28490761  1.43215212]\n",
            " [ 1.33410866  0.06054564 -1.84826245 -2.15770661  1.44517411]\n",
            " [ 0.38083111 -0.34465047  1.609933   -0.42978173 -1.04560822]\n",
            " [-1.10964532  0.8204219   0.21775673  0.54710765 -0.54322134]\n",
            " [-0.41343272  0.16616504 -0.9829129   0.04263262 -0.64121387]\n",
            " [ 0.66484284 -0.4852942   0.00662931 -0.63468741 -0.36190936]\n",
            " [ 1.17032876 -0.52829922 -0.06004014 -0.38591708 -0.70600685]\n",
            " [-1.23918553  0.12967573  1.78177281  1.21974542 -2.16340771]\n",
            " [-0.34989569 -0.41970439 -0.19709476 -1.08905456  0.14272398]\n",
            " [-0.22517994  0.18923135 -0.88342032 -0.83948699 -0.00302335]]\n",
            "입력계층과 첫 번째 은닉계층 사이의 편향 : \n",
            " [0. 0. 0. 0. 0.]\n",
            "첫 번째 은닉계층과 두 번째 은닉계층 사이의 가중치 : \n",
            " [[-0.81522672 -0.36561488  2.48021637]\n",
            " [-0.21257075 -1.17264512 -0.45427159]\n",
            " [-0.94657198 -1.62409226 -0.13202497]\n",
            " [ 0.48872685 -0.16915045 -0.55777559]\n",
            " [ 0.67713853 -2.98967838 -1.24882501]]\n",
            "첫 번째 은닉계층과 두 번째 은닉계층 사이의 편향 : \n",
            " [0. 0. 0.]\n",
            "두 번째 은닉계층과 출력계층 사이의 가중치 : \n",
            " [[-2.23301313]\n",
            " [ 0.97547376]\n",
            " [-0.5744491 ]]\n",
            "두 번째 은닉계층과 출력계층 사이의 편향 : \n",
            " [0.]\n"
          ]
        }
      ],
      "source": [
        "# # [테스트 코드]\n",
        "# # 다층 퍼셉트론 신경망 구조 설정\n",
        "# input_cnt = 10    # 입력계층의 노드 수 10개 \n",
        "# set_hidden([5,3]) # 은닉계층들의 노드 수 각 5개, 3개\n",
        "# output_cnt = 1    # 출력계층의 노드 수 1개 \n",
        "\n",
        "# # 파라미터 초기화 메서드 동작 시나리오\n",
        "# # init_param() -> init_param_hiddens() -> allocate_param_pair()\n",
        "# init_param()\n",
        "\n",
        "# print(\"입력계층과 첫 번째 은닉계층 사이의 가중치 : \\n\", pm_hiddens[0]['w'])\n",
        "# print(\"입력계층과 첫 번째 은닉계층 사이의 편향 : \\n\", pm_hiddens[0]['b'])\n",
        "# print(\"첫 번째 은닉계층과 두 번째 은닉계층 사이의 가중치 : \\n\", pm_hiddens[1]['w'])\n",
        "# print(\"첫 번째 은닉계층과 두 번째 은닉계층 사이의 편향 : \\n\", pm_hiddens[1]['b'])\n",
        "# print(\"두 번째 은닉계층과 출력계층 사이의 가중치 : \\n\", pm_output['w'])\n",
        "# print(\"두 번째 은닉계층과 출력계층 사이의 편향 : \\n\", pm_output['b'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "B5J-HcVPgGhB"
      },
      "outputs": [],
      "source": [
        "# 활성화 함수 ReLU() 정의 \n",
        "def relu(x):\n",
        "    # 음수와 0을 걸러주는 numpy 내부 메서드 활용 \n",
        "    return np.maximum(x,0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_7jOV14agwPu",
        "outputId": "79e4bb4c-9bc4-4634-c00a-f7e0e28d2be4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "relu(-3) : 0\n",
            "relu(-2) : 0\n",
            "relu(-1) : 0\n",
            "relu(0) : 0\n",
            "relu(1) : 1\n",
            "relu(2) : 2\n",
            "relu(3) : 3\n"
          ]
        }
      ],
      "source": [
        "# # [테스트 코드]\n",
        "# for x in range(-3,4,1):\n",
        "#     print(f\"relu({x}) : {relu(x)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "ORE785O-gxYc"
      },
      "outputs": [],
      "source": [
        "# 순전파를 수행하는 메서드 정의\n",
        "def forward_neuralnet_hidden1(x):\n",
        "\n",
        "    global pm_output, pm_hidden\n",
        "    \n",
        "    # hidden : 은닉계층의 각 노드가 갖는 값\n",
        "    # 은닉계층의 가중치와 편향을 활용해 독립변수와의 연산 후 비선형 활성화 함수 relu() 적용\n",
        "    hidden = relu(np.matmul(x, pm_hidden['w']) + pm_hidden['b'])\n",
        "\n",
        "    # output : 출력계층의 각 노드가 갖는 값 \n",
        "    # 출력 계층에 대한 선형 연산\n",
        "    output = np.matmul(hidden, pm_output['w']) + pm_output['b']\n",
        "\n",
        "    # 반환되어지는 값은 최종 연산 결괏값과 역전파에 활용되는 각 계층별 변수 \n",
        "    return output, [x,hidden]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vTajXsPXg6Ey",
        "outputId": "1d1b323b-03de-4e60-dcd3-5d377b1d9975"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[안내] 은닉 계층 하나를 갖는 다층 퍼셉트론이 적용됩니다.\n",
            "순전파 연산 결괏값(output) :  [2.75147794]\n",
            "순전파 중간연산 결괏값(hidden) :  [1.97946461 0.633984  ]\n",
            "독립변수(x) :  [1.23 0.31 2.31]\n"
          ]
        }
      ],
      "source": [
        "# # [테스트 코드]\n",
        "# # 더미데이터 생성\n",
        "# x = np.asarray([1.23, 0.31, 2.31])\n",
        "# # 더미데이터에 따른 신경망 노구조 결정\n",
        "# input_cnt = 3  \n",
        "# set_hidden(2)\n",
        "# output_cnt = 1\n",
        "\n",
        "# # 파라미터 초기화 메서드 동작\n",
        "# init_param()\n",
        "# # 순전파 연산 메서드 동작 \n",
        "# result = forward_neuralnet(x)\n",
        "\n",
        "# print(\"순전파 연산 결괏값(output) : \", result[0])\n",
        "# print(\"순전파 중간연산 결괏값(hidden) : \", result[1][1])\n",
        "# print(\"독립변수(x) : \", result[1][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "gVXSQCSZg81w"
      },
      "outputs": [],
      "source": [
        "# 하나 이상의 은닉계층이 존재하는 경우 순전파 메서드 정의\n",
        "# x : 독립변수\n",
        "def forward_neuralnet_hiddens(x):\n",
        "    # pm_hiddens : 입력계층과 은닉계층들 사이의 파라미터(리스트, 딕셔너리)\n",
        "    # pm_output  : 마지막 은닉계층과 출력계층 사이의 파라미터(딕셔너리)\n",
        "    global pm_output, pm_hiddens\n",
        "\n",
        "    # 입력계층의 데이터(독립변수)\n",
        "    hidden = x    # 연산용\n",
        "    hiddens = [x] # 역전파 전달용 보조정보(기존값 포함)\n",
        "\n",
        "    # 반복문을 통해 은닉계층들의 파라미터 정보를 하나씩 전달받도록 함 \n",
        "    # 입력계층부터 마지막 은닉계층까지의 연산을 진행\n",
        "    # 선형연산 결괏값 다음은 relu 적용 \n",
        "    for pm_hidden in pm_hiddens:\n",
        "\n",
        "        hidden = relu(np.matmul(hidden, pm_hidden['w']) + pm_hidden['b'])\n",
        "        # 연산 결괏값의 할당\n",
        "        hiddens.append(hidden)\n",
        "\n",
        "    # 마지막 은닉계층까지의 연산결괏값과 출력계층의 파라미터의 연산\n",
        "    # 활성화 함수 적용 X\n",
        "    output = np.matmul(hidden, pm_output['w']) + pm_output['b']\n",
        "\n",
        "    # 연산 결괏값(output) 반환 및 경사하강법 적용을 위해 hiddens 반환 \n",
        "    return output, hiddens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y8gJ2e1_hFqB",
        "outputId": "5517409c-040f-4e1b-cf2b-0094fbbb78f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[안내] 은닉 계층 2개를 갖는 다층 퍼셉트론이 적용됩니다.\n",
            "독립변수(x) :  [1.23 0.31 2.31 0.3  2.13]\n",
            "첫 번째 은닉계층 연산 결괏값(hiddens) :  [0.99346946 3.58635278 0.        ]\n",
            "두 번째 은닉계층 연산 결괏값(hiddens) :  [0.2124883 0.       ]\n",
            "순전파 연산 결괏값(output) :  [-0.60328267]\n"
          ]
        }
      ],
      "source": [
        "# # 테스트 코드\n",
        "# # 더미데이터 생성\n",
        "# x = np.asarray([1.23, 0.31, 2.31, 0.3, 2.13])\n",
        "# # 더미데이터에 따른 신경망 노구조 결정\n",
        "# input_cnt = 5  \n",
        "# set_hidden([3,2])\n",
        "# output_cnt = 1\n",
        "\n",
        "# # 파라미터 초기화 메서드 동작\n",
        "# init_param()\n",
        "# # 순전파 연산 메서드 동작 \n",
        "# result = forward_neuralnet(x)\n",
        "\n",
        "# print(\"독립변수(x) : \", result[1][0])\n",
        "# print(\"첫 번째 은닉계층 연산 결괏값(hiddens) : \", result[1][1])\n",
        "# print(\"두 번째 은닉계층 연산 결괏값(hiddens) : \", result[1][2])\n",
        "# print(\"순전파 연산 결괏값(output) : \", result[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "lDoMSICVhI_C"
      },
      "outputs": [],
      "source": [
        "# 활성화 함수 ReLU 는 np.sign() 메서드로 구현할 수 있으며, 다음과 같은 특징을 갖습니다. \n",
        "# -1 if x < 0\n",
        "# 0 if x==0\n",
        "# 1 if x > 0\n",
        "def relu_derv(y):\n",
        "    return np.sign(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "7k6WjHywhagh"
      },
      "outputs": [],
      "source": [
        "# 파라미터 갱신을 수행하는 메서드 \n",
        "# G_output : 출력계층과 은닉계층 사이의 ∂L/∂Y\n",
        "# aux : 입력 벡터, 은닉 계층의 정보 \n",
        "def backprop_neuralnet_hidden1(G_output, aux):\n",
        "    \n",
        "    # pm_hidden : 입력계층과 은닉계층 사이의 파라미터\n",
        "    # pm_output : 은닉계층과 출력계층 사이의 파라미터    \n",
        "    global pm_output, pm_hidden\n",
        "    \n",
        "    # 입력 벡터, 은닉계층의 노드 값 각각 변수화 \n",
        "    x, hidden = aux\n",
        "\n",
        "    # [출력계층과 은닉계층 사이의 파라미터 갱신 준비과정]\n",
        "    # 가중치 갱신 준비과정 : X^t * G\n",
        "    g_output_w_output = hidden.transpose()\n",
        "    G_w_out = np.matmul(g_output_w_output, G_output)\n",
        "    # 편향 갱신 준비과정 : G\n",
        "    G_b_out = np.sum(G_output, axis = 0)\n",
        "\n",
        "    # [G_hidden 생성과정 1단계] \n",
        "    # G_Hidden : 은닉계층과 입력계층 사이의 ∂L/∂Y\n",
        "    # 전체 수식 : (𝛅_k * w_k) * 𝜑(h)\n",
        "    # 1단계에서 구현하는 수식 : (𝛅_k * w_k)\n",
        "     \n",
        "    # np.matmul() 연산 과정을 위해 행렬전환\n",
        "    # G_hidden 을 구하기 위해서는 업데이트가 되지 않은 가중치가 필요하기에 \n",
        "    # 가중치 업데이트 전에 활용\n",
        "    g_output_hidden = pm_output['w'].transpose()\n",
        "    G_hidden = np.matmul(G_output, g_output_hidden)\n",
        "\n",
        "    # 출력계층과 은닉계층 사이의 파라미터 갱신\n",
        "    pm_output['w'] -= LEARNING_RATE * G_w_out\n",
        "    pm_output['b'] -= LEARNING_RATE * G_b_out\n",
        "\n",
        "\n",
        "    # [G_hidden 생성과정 2단계] \n",
        "    # G_Hidden : 은닉계층과 입력계층 사이의 ₩\n",
        "    # 전체 수식 : (𝛅_k * w_k) * 𝜑(h)\n",
        "    # 2단계에서 구현하는 수식 : (𝛅_k * w_k) * 𝜑(h)\n",
        "    # 은닉계층에서 비선형 활성화함수 relu가 사용되므로, 이에 따른 미분과정의 곱이 수행 \n",
        "    G_hidden = G_hidden * relu_derv(hidden)\n",
        "\n",
        "    # 은닉계층과 입력계층 사이의 파라미터 갱신준비과정\n",
        "    # 가중치 갱신 준비과정\n",
        "    g_hidden_w_hid = x.transpose()\n",
        "    G_w_hid = np.matmul(g_hidden_w_hid, G_hidden)\n",
        "    # 편향 갱신 준비과정\n",
        "    G_b_hid = np.sum(G_hidden, axis=0)\n",
        "\n",
        "    # 은닉계층과 입력계층 사이의 파리미터 갱신 \n",
        "    pm_hidden['w'] -= LEARNING_RATE * G_w_hid\n",
        "    pm_hidden['b'] -= LEARNING_RATE * G_b_hid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "VCsX90akhf55"
      },
      "outputs": [],
      "source": [
        "# 파라미터 업데이트 매서드 \n",
        "# G_output : 가장 마지막 계층의 ∂L/∂Y (delta_k)\n",
        "# aux : 독립변수, 은닉계층들이 갖는 노드 값 \n",
        "def backprop_neuralnet_hiddens(G_output, aux):\n",
        "    global pm_output, pm_hiddens\n",
        "\n",
        "    # 독립변수와 은닉계층들의 노드값들을 hiddens 에 저장(리스트 타입)\n",
        "    hiddens = aux \n",
        "\n",
        "    # [출력계층과 마지막 은닉계층 사이의 파라미터 갱신 준비]\n",
        "    # 가중치 갱신에 필요한 수식 : ∂L/∂W (X^t * G)\n",
        "    # 가장 마지막 은닉 계층(hiddens[-1])의 행렬전환 \n",
        "    g_output_w_out = hiddens[-1].transpose()\n",
        "    G_w_out = np.matmul(g_output_w_out, G_output)\n",
        "    # 편향 갱신에 필요한 수식 : ∂L/∂B (G)\n",
        "    G_b_out = np.sum(G_output, axis = 0)\n",
        "\n",
        "    # [마지막 은닉계층과 이전 은닉계층의 ∂L/∂Y (delta_k+1) 준비 - 1/2 단계]\n",
        "    # 업데이트가 되지 않은 가중치가 필요 \n",
        "    g_output_hidden = pm_output['w'].transpose()\n",
        "    G_hidden = np.matmul(G_output, g_output_hidden)\n",
        "\n",
        "    # [출력계층과 마지막 은닉계층 사이의 파라미터 갱신]\n",
        "    # 출력계층과 마지막 은닉계층의 파라미터 업데이트\n",
        "    pm_output['w'] -= LEARNING_RATE * G_w_out\n",
        "    pm_output['b'] -= LEARNING_RATE * G_b_out\n",
        "\n",
        "    # 마지막 은닉 계층과 그 이전 계층들 사이의 파라미터 업데이트 과정\n",
        "    # 즉 뒤에서 부터 업데이트를 하기 위해 reversed() 를 활용\n",
        "    # reversed() : 주어진 값들을 거꾸로 반환\n",
        "    # pm_hiddens : 입력벡터 부터 마지막 은닉계층의 값을 담고 있음 (리스트)\n",
        "    for n in reversed(range(len(pm_hiddens))):\n",
        "        \n",
        "        # [마지막 은닉계층과 이전 은닉계층의 ∂L/∂Y (delta_k+1) 준비 - 2/2단계]\n",
        "        # 2단계에서 구현하는 수식 : (𝛅_k * w_k) * 𝜑(h)\n",
        "        # 𝜑(h)에 매개변수는 가장 마지막 은닉계층의 값부터 순차적으로 들어와야함\n",
        "        G_hidden = G_hidden * relu_derv(hiddens[n+1])\n",
        "\n",
        "        # 가장 마지막 이전 계층의 파라미터 갱신 준비\n",
        "        g_hidden_w_hid = hiddens[n].transpose()\n",
        "        G_w_hid = np.matmul(g_hidden_w_hid, G_hidden)\n",
        "        G_b_hid = np.sum(G_hidden, axis = 0)\n",
        "\n",
        "        # 마지막 은닉계층의 이전 계층 ∂L/∂Y 연산 (𝛅_k * w_k)\n",
        "        g_hidden_hidden = pm_hiddens[n]['w'].transpose()\n",
        "        G_hidden = np.matmul(G_hidden, g_hidden_hidden)\n",
        "\n",
        "        # 마지막 은닉계층 이전 계층의 파라미터 갱신\n",
        "        pm_hiddens[n]['w'] -= LEARNING_RATE * G_w_hid\n",
        "        pm_hiddens[n]['b'] -= LEARNING_RATE * G_b_hid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2GeVOXfYhiFI"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
